---
title: "DATA 621: BUSINESS ANALYTICS AND DATA MINING HOMEWORK#5 Assignment Requirements"
date: "Last edited `r format(Sys.time(), '%B %d, %Y')`"
author: "Group 2 - Gabriel Campos, Melissa Bowman, Alexander Khaykin, & Jennifer Abinette"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 4
    number_sections: true
    highlight: tango
  geometry: "left=0.5cm,right=0.5cm,top=0.5cm,bottom=0.5cm"
  html_document:
    df_print: paged
urlcolor: blue
---

# Overview

&emsp; In this homework assignment, you will explore, analyze and model a data set containing information on
approximately 12,000 commercially available wines. The variables are mostly related to the chemical properties of
the wine being sold. The response variable is the number of sample cases of wine that were purchased by wine
distribution companies after sampling a wine. These cases would be used to provide tasting samples to
restaurants and wine stores around the United States. The more sample cases purchased, the more likely is a
wine to be sold at a high end restaurant. A large wine manufacturer is studying the data in order to predict the
number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the
number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales.

&emsp; Your objective is to build a count regression model to predict the number of cases of wine that will be sold
given certain properties of the wine. HINT: Sometimes, the fact that a variable is missing is actually predictive of
the target. You can only use the variables given to you (or variables that you derive from the variables provided).
Below is a short description of the variables of interest in the data set:
<br>

```{r, echo=FALSE, message=FALSE}
library('dplyr')
library('tidyverse')
library('kableExtra')

#Added
library(ggplot2)
library(MASS)   # For negative binomial regression
library(pscl)   # For hurdle and zero-inflated models
library(Metrics) # For model evaluation metrics
library(skimr)
```

```{r, echo=FALSE}
ls_c1 <-c("INDEX", "TARGET","","", "AcidIndex", "Alcohol",
          "Chlorides", "CitricAcid", "Density", "FixedAcidity",
          "FreeSulfurDioxide", "LabelAppeal", "ResidualSugar", "STARS",
          "Sulphates", "TotalSulfurDioxide", "VolatileAcidity", "pH")

ls_c2 <- c("Identification Variable (do not use)",
           "Number of Cases Purchased","","",
           paste("Proprietary method of testing total acidity of wine by",
                 " using a weighted average"),
           "Alcohol Content", "Chloride content of wine", "Citric Acid Content",
           "Density of Wine", "Fixed Acidity of Wine",
           "Sulfur Dioxide content of wine",
           paste("Marketing Score indicating the appeal of label design for",
                 " consumers. High numbers suggest customers like the label",
                 " design. Negative numbers suggest customes don't like the",
                 " design."),
           "Residual Sugar of wine",
           paste("Wine rating by a team of experts.",
                 " 4 Stars = Excellent, 1 Star = Poor"),
           "Sulfate conten of wine","Total Sulfur Dioxide of Wine",
           "Volatile Acid content of wine", "pH of wine")

ls_c3 <- c("None", "None","","", "", "", "", "", "", "", "",
           paste("Many consumers purchase based on the visual appeal of",
                 " the wine label design. Higher numbers suggest better",
                 " sales."),
           "", "A high number of stars suggests high sales", "", "", "", "")  
  
df_overview <- data.frame(column1 = ls_c1,
                            DEFINITION = ls_c2,
                            column3 = ls_c3)%>%
                              rename(`VARIABLE NAME` = column1, 
                                     `THEORETICAL EFFECT` = column3)

df_overview%>%
  kable()%>%
    kable_styling(latex_options = c('scale_down','HOLD_position'))%>%
      column_spec(2, width = "20em")%>%
        column_spec(3, width = "20em")
```

```{r, echo=FALSE}
rm(ls_c1,ls_c2,ls_c3,df_overview)
```

## Deliverables

* A write-up submitted in PDF format. Your write-up should have four sections. Each one is described below. You may assume you are addressing me as a fellow data scientist, so do not need to shy away from technical details.
* Assigned predictions (number of cases of wine sold) for the evaluation data set.
* Include your R statistical programming code in an Appendix.

## Write Up:

### 1. DATA EXPLORATION (25 Points)

Describe the size and the variables in the wine training data set. Consider that too much detail will cause a
manager to lose interest while too little detail will make the manager consider that you aren’t doing your job. Some
suggestions are given below. Please do NOT treat this as a check list of things to do to complete the assignment.
You should have your own thoughts on what to tell the boss. These are just ideas.

a. Mean / Standard Deviation / Median
b. Bar Chart or Box Plot of the data
c. Is the data correlated to the target variable (or to other variables?)
d. Are any of the variables missing and need to be imputed “fixed”?

### 2. DATA PREPARATION (25 Points)

Describe how you have transformed the data by changing the original variables or creating new variables. If you did transform the data or create new variables, discuss why you did this. Here are some possible transformations.

a. Fix missing values (maybe with a Mean or Median value)
b. Create flags to suggest if a variable was missing
c. Transform data by putting it into buckets
d. Mathematical transforms such as log or square root (or use Box-Cox)
e. Combine variables (such as ratios or adding or multiplying) to create new variables

### 3. BUILD MODELS (25 Points)

Using the training data set, build at least two different poisson regression models, at least two different negative binomial regression models, and at least two multiple linear regression models, using different variables (or the same variables with different transformations). Sometimes poisson and negative binomial regression models give the same results. If that is the case, comment on that. Consider changing the input variables if that occurs so that you get different models. Although not covered in class, you may also want to consider building zero-inflated poisson and negative binomial regression models. You may select the variables manually, use an approach such as Forward or Stepwise, use a different approach such as trees, or use a combination of techniques. Describe the techniques you used. If you manually selected a variable for inclusion into the model or exclusion into the model, indicate why this was done 


Discuss the coefficients in the models, do they make sense? In this case, about the only thing you can comment on is the number of stars and the wine label appeal. However, you might comment on the coefficient and magnitude of variables and how they are similar or different from model to model. For example, you might say “pH seems to have a major positive impact in my poisson regression model, but a negative effect in my multiple linear regression model”. Are you keeping the model even though it is counter intuitive? Why? The boss needs to know.


### 4. SELECT MODELS (25 Points)

Decide on the criteria for selecting the best count regression model. Will you select models with slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected your models.

For the count regression model, will you use a metric such as AIC, average squared error, etc.? Be sure to explain how you can make inferences from the model, and discuss other relevant model output. If you like the multiple linear regression model the best, please say why. However, you must select a count regression model for model deployment. Using the training data set, evaluate the performance of the count regression model. Make predictions using the evaluation data set.

# Import Data

```{r, echo=FALSE}
url_git <- "https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"
```

```{r}
df_wine_eval <- 
  read.csv(paste0(url_git,"wine-evaluation-data.csv"))

head(df_wine_eval)
```

```{r}
df_wine_train <- 
  read.csv(paste0(url_git,"wine-training-data.csv"))
head(df_wine_train)
```
Of training variable:
```{r}
print(skim(df_wine_train))
```

```{r}
summary(df_wine_train)
```
Of evaluated variable:

```{r}
print(skim(df_wine_eval))
```

```{r}
summary(df_wine_eval)
```


Looking at histogram

```{r}
# Gather the data into a long format
data_long <- gather(df_wine_train, key = "Variable", value = "Value")

ggplot(data_long, aes(x = Value)) +
  geom_histogram() +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histogram of Variables")
```

Relatively normal data. We do not have to correct any variables 
```{r}
# Create a correlation matrix for all variables
(cor_matrix <- cor(df_wine_train, use='complete.obs'))
```

Only 3 real variable that relate to TARGET which are LabelAppeal, AcidIndex, STARS. STARS though has a lot of NA values 


```{r}
df_wine_train %>% 
  mutate(STARS = as.factor(STARS),
         TARGET = as.factor(TARGET)) %>% 
  ggplot(aes(STARS)) +
  geom_bar(aes(fill = TARGET)) +
  scale_fill_brewer(palette = "RdYlGn") 
```

Because STARS has a lot of NA values that relate to a TARGET value of 0 we should make STARS NA zero instead of eliminating NA values.  
```{r}
df_wine_train_transformed <- df_wine_train %>% 
    mutate(STARS = replace(STARS, is.na(STARS) , 0))

df_wine_eval_transformed  <- df_wine_eval %>% 
    mutate(STARS = replace(STARS, is.na(STARS) , 0))
```

(Might not need this histogram)
```{r}
# Plot a histogram
hist(df_wine_train$TARGET, main = "Histogram of TARGET", xlab = "TARGET", col = "skyblue", border = "black")
```

```{r}
# Calculate the percentage of unique values in the TARGET variable
target_table <- table(df_wine_train$TARGET)
target_percentage <- prop.table(target_table) * 100


rounded_percentage <- round(target_percentage, 2)


print(rounded_percentage)
```
Since there are an excess of zero values in the data set, the Poisson and Negative Binomial Regression may not be able to give the best model outcome. Therefore, we will also test Hurdle Poisson and Zero-Inflated Poisson Regression models to see if these models work best. To compare these models, we will be using the The Root Mean Squared Error (RMSE). The lowest number will tell us which model works best. 

Train-test split
```{r}
set.seed(100)  
n <- nrow(df_wine_train_transformed)
train_index <- sample(1:n, 0.8 * n)  # 80% for training, 20% for testing
df_train <- df_wine_train_transformed[train_index, ]
df_test <- df_wine_train_transformed[-train_index, ]
```

#Poisson Regression
Model
```{r}
poisson_model <- glm(TARGET ~ LabelAppeal + AcidIndex + STARS, data = df_train, family = poisson)
#summary(poisson_model)
```

Prediction of test-split data (will need to be rounded to full numbers?)
```{r}
poisson_preds <- predict(poisson_model, newdata = df_test, type = "response")
```

RMSE
```{r}
poisson_rmse <- sqrt(mean((poisson_preds - df_test$TARGET)^2))
```


# Negative Binomial Regression
Model
```{r}
neg_binom_model <- glm.nb(TARGET ~ LabelAppeal + AcidIndex + STARS, data = df_train)
#summary(neg_binom_model)
```

Prediction of test-split data (will need to be rounded to full numbers?)
```{r}
neg_binom_preds <- predict(neg_binom_model, newdata = df_test, type = "response")
```

RMSE
```{r}
neg_binom_rmse <- sqrt(mean((neg_binom_preds - df_test$TARGET)^2))
```

# Hurdle Poisson Regression
Model
```{r}
hurdle_poisson_model <- hurdle(TARGET ~ LabelAppeal + AcidIndex + STARS, data = df_train, dist = "poisson")
#summary(hurdle_poisson_model)
```

Prediction of test-split data (will need to be rounded to full numbers?)
```{r}
hurdle_preds <- predict(hurdle_poisson_model, newdata = df_test, type = "response")
```

RMSE
```{r}
hurdle_rmse <- sqrt(mean((hurdle_preds - df_test$TARGET)^2))
```

# Zero-Inflated Poisson Regression
Model
```{r}
zip_model <- zeroinfl(TARGET ~ LabelAppeal + AcidIndex + STARS | 1, data = df_train, dist = "poisson")
summary(zip_model)
```

Prediction of test-split data (will need to be rounded to full numbers?)
```{r}
zip_preds <- predict(zip_model, newdata = df_test, type = "response")
```

RMSE
```{r}
zip_rmse <- sqrt(mean((zip_preds - df_test$TARGET)^2))
```

# Compare RMSE
```{r}
comparison <- data.frame(
  Model = c("Poisson", "Negative Binomial", "Hurdle Poisson", "Zero-Inflated Poisson"),
  RMSE = c(poisson_rmse, neg_binom_rmse, hurdle_rmse, zip_rmse)
)

print(comparison)
```
# Predict using the hurdle_poisson_model
```{r}
eval_preds <- predict(hurdle_poisson_model, newdata = df_wine_eval_transformed, type = "response")
```

