---
title: "DATA 621: BUSINESS ANALYTICS AND DATA MINING HOMEWORK#3: LOGISTIC REGRESSION"
date: "Last edited `r format(Sys.time(), '%B %d, %Y')`"
author: "Group 2 - Gabriel Campos, Melissa Bowman, Alexander Khaykin, & Jennifer Abinette"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    number_sections: true
    highlight: tango
  geometry: "left=0.5cm,right=0.5cm,top=1cm,bottom=2cm"
  html_document:
    df_print: paged
urlcolor: blue
---

# Overview

In this homework assignment, you will explore, analyze and model a data set containing information on
crime for various neighborhoods of a major city. Each record has a response variable indicating whether
or not the crime rate is above the median crime rate (1) or not (0).

Your objective is to build a *binary logistic regression model* on the training data set to predict whether
the neighborhood will be at risk for high crime levels. You will provide classifications and probabilities
for the evaluation data set using your binary logistic regression model. You can only use the variables
given to you (or, variables that you derive from the variables provided). Below is a short description of
the variables of interest in the data set:

* zn: proportion of residential land zoned for large lots (over 25000 square feet) (predictor variable)
* indus: proportion of non-retail business acres per suburb (predictor variable)
* chas: a dummy var. for whether the suburb borders the Charles River (1) or not (0) (predictor variable)
* nox: nitrogen oxides concentration (parts per 10 million) (predictor variable)
* rm: average number of rooms per dwelling (predictor variable)
* age: proportion of owner-occupied units built prior to 1940 (predictor variable)
* dis: weighted mean of distances to five Boston employment centers (predictor variable)
* rad: index of accessibility to radial highways (predictor variable)
* tax: full-value property-tax rate per $10,000 (predictor variable)
* ptratio: pupil-teacher ratio by town (predictor variable)
* lstat: lower status of the population (percent) (predictor variable)
* medv: median value of owner-occupied homes in $1000s (predictor variable)
* **target: whether the crime rate is above the median crime rate (1) or not (0) (response variable)**

# Deliverables:

* A write-up submitted in PDF format. Your write-up should have four sections. Each one is described
below. You may assume you are addressing me as a fellow data scientist, so do not need to shy away
from technical details.
* Assigned prediction (probabilities, classifications) for the evaluation data set. Use 0.5 threshold.
Include your R statistical programming code in an Appendix.

# **Write Up:**
**1. DATA EXPLORATION (25 Points)**
Describe the size and the variables in the crime training data set. Consider that too much detail will cause
a manager to lose interest while too little detail will make the manager consider that you aren’t doing
your job. Some suggestions are given below. Please do NOT treat this as a check list of things to do to
complete the assignment. You should have your own thoughts on what to tell the boss. These are just
ideas.
a. Mean / Standard Deviation / Median
b. Bar Chart or Box Plot of the data
c. Is the data correlated to the target variable (or to other variables?)
d. Are any of the variables missing and need to be imputed/“fixed”?

**2. DATA PREPARATION (25 Points)**
Describe how you have transformed the data by changing the original variables or creating new variables.
If you did transform the data or create new variables, discuss why you did this. Here are some possible
transformations.
a. Fix missing values (maybe with a Mean or Median value)
b. Create flags to suggest if a variable was missing
c. Transform data by putting it into buckets
d. Mathematical transforms such as log or square root (or, use Box-Cox)
e. Combine variables (such as ratios or adding or multiplying) to create new variables

**3. BUILD MODELS (25 Points)**
Using the training data, build at least three different binary logistic regression models, using different
variables (or the same variables with different transformations). You may select the variables manually,
use an approach such as Forward or Stepwise, use a different approach, or use a combination of
techniques. Describe the techniques you used. If you manually selected a variable for inclusion into the
model or exclusion into the model, indicate why this was done.
Be sure to explain how you can make inferences from the model, as well as discuss other relevant model
output. Discuss the coefficients in the models, do they make sense? Are you keeping the model even
though it is counter intuitive? Why? The boss needs to know.

**4. SELECT MODELS (25 Points)**
Decide on the criteria for selecting the best binary logistic regression model. Will you select models with
slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected
your model.
* For the binary logistic regression model, will you use a metric such as log likelihood, AIC, ROC curve,
etc.? Using the training data set, evaluate the binary logistic regression model based on (a) accuracy, (b)
classification error rate, (c) precision, (d) sensitivity, (e) specificity, (f) F1 score, (g) AUC, and (h)
confusion matrix. Make predictions using the evaluation data set

\newpage

# Data Exploration

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)

#What I added
library(scales)
library(MASS)
```


## **Load the data**
```{r data-import}
git_url<-
  "https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"

```

```{r}

df_crime_eval <- 
  read.csv(paste0(git_url,"crime-evaluation-data_modified.csv"))
head(df_crime_eval,n=10)

```

```{r}
df_crime_eval
```


```{r}
df_crime_train <- 
  read.csv(paste0(git_url,"crime-training-data_modified.csv"))
head(df_crime_train,n=10)
```

```{r}
df_crime_eval[is.na(df_crime_eval)]
```
```{r}
df_crime_train[is.na(df_crime_train)]
```
```{r}
summary(df_crime_eval)
```

```{r}
summary(df_crime_train)
```


```{r}
str(df_crime_train)
```
Checking to see if data is categorical

```{r}
xtabs(~ target + medv ,  data = df_crime_train)
```
```{r}
# Create a correlation matrix for all variables
(cor_matrix <- cor(df_crime_train))
```

The logistic regression model dependant variable target has 


Changing categorical data into factors to  ensure that the model can appropriately interpret and analyze categorical variables.Change after looking at collinearity.

```{r}
#Don't use this
#df_crime_train$chas <- as.factor(df_crime_train$chas)
#df_crime_train$rad <- as.factor(df_crime_train$rad)
#df_crime_train$target <- as.factor(df_crime_train$target)
```

```{r}
str(df_crime_train)
```
```{r}
model_1 <- glm(formula = target ~ ., family = binomial, data = df_crime_train)

summary(model_1)
```

```{r}
# Gather the data into a long format
data_long <- gather(df_crime_train, key = "Variable", value = "Value")

ggplot(data_long, aes(x = Value)) +
  geom_histogram() +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histogram of Variables")
```
Variable here are not normalized and those normalized need to be on the same scale as the others to make data more interpretable.  

******** I need to rescale after normalizing. 
```{r}
# Apply min-max scaling to all three variables
data_scaled <- df_crime_train
data_scaled[] <- lapply(df_crime_train, rescale)
```


```{r}
# Gather the data into a long format
data_long_scaled <- gather(data_scaled, key = "Variable", value = "Value")

ggplot(data_long_scaled, aes(x = Value)) +
  geom_histogram() +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histogram of Variables")
```

Checking correlation of scaled varibles 

```{r}
# Create a correlation matrix for all variables
(cor_matrix <- cor(data_scaled))
```

```{r}
model_2 <- glm(formula = target ~ ., family = binomial, data = data_scaled)

(summary=(model_2))
```


```{r}
df_crime_train$age <- as.numeric(df_crime_train$age)
```



```{r}

# Convert a DataFrame column to a list
age_list <- as.numeric(as.list(df_crime_train$age))

#find optimal lambda for Box-Cox transformation 
bc <- boxcox(age_list~ 1, lambda = seq(-2,2,0.1))
lambda <- bc$x[which.max(bc$y)]

# Apply the Box-Cox transformation
age_new = (age_list^lambda-1)/lambda
```

```{r}
hist(age_new)
hist(df_crime_train$age)
```

```{r}
# Convert a DataFrame column to a list
dis_list <- as.numeric(as.list(df_crime_train$dis))

#find optimal lambda for Box-Cox transformation 
bc <- boxcox(dis_list~ 1, lambda = seq(-2,2,0.1))
lambda_dis <- bc$x[which.max(bc$y)]

# Apply the Box-Cox transformation
dis_new = (dis_list^lambda_dis-1)/lambda_dis
```

```{r}
hist(dis_new)
hist(df_crime_train$dis)
```
```{r}
# Convert a DataFrame column to a list
indus_list <- as.numeric(as.list(df_crime_train$indus))

#find optimal lambda for Box-Cox transformation 
bc <- boxcox(indus_list~ 1, lambda = seq(-2,2,0.1))
lambda_indus <- bc$x[which.max(bc$y)]

# Apply the Box-Cox transformation
indus_new = (indus_list^lambda_indus-1)/lambda_indus


hist(indus_new )
hist(df_crime_train$indus)
```



```{r}
# Create an empty list to store the transformed columns
transformed_columns <- list()

# Define the names of columns to exclude from transformation because there variables response must be positive 
exclude_columns <- c("target", "zn", "chas")  

# Iterate through the columns in df_crime_train
for (col_name in names(df_crime_train)) {
  # Convert the column to a list and check if it's numeric and not in the exclude list
  if (is.numeric(df_crime_train[[col_name]]) && !(col_name %in% exclude_columns)) {
    col_list <- as.numeric(as.list(df_crime_train[[col_name]]))
    
    # Find optimal lambda for Box-Cox transformation
    bc <- boxcox(col_list ~ 1, lambda = seq(-2, 2, 0.1))
    lambda_col <- bc$x[which.max(bc$y)]
    
    # Apply the Box-Cox transformation
    col_new <- ifelse(col_list==0, log(col_list), (col_list^lambda_col - 1) / lambda_col)
    
    # Store the transformed column in the list
    transformed_columns[[col_name]] <- col_new
  }
}

# Convert the list of transformed columns into a DataFrame
df_transformed <- as.data.frame(transformed_columns)
```

```{r}
# Gather the data into a long format
data_transformed_long <- gather(df_transformed, key = "Variable", value = "Value")

ggplot(data_transformed_long, aes(x = Value)) +
  geom_histogram() +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histogram of Variables")
# (dis_t, lstat_t, medv_t, nox_t)
```


```{r}
# Gather the data into a long format
data_long <- gather(df_crime_train, key = "Variable", value = "Value")

ggplot(data_long, aes(x = Value)) +
  geom_histogram() +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histogram of Variables")
```

```{r}
# Move 
df_crime_train_with_transformed <- df_transformed %>%
  dplyr::select(dis, lstat, medv, nox) %>%
  mutate(dis_t = dis, lstat_t = lstat, medv_t = medv, nox_t = nox)%>%
                dplyr::select(-c(dis, lstat, medv, nox))
```


```{r}
# Combine data frames by adding columns
result <- cbind(df_crime_train_with_transformed, df_crime_train %>%
                dplyr::select(-c(dis, lstat, medv, nox)))
```


```{r}
# Create a correlation matrix for all variables
(cor_matrix <- cor(result))
```


```{r}
# Apply min-max scaling to all three variables
data_scaled <- result
data_scaled[] <- lapply(result, rescale)
```


```{r}
# Gather the data into a long format
df_crime_train_with_transformed <- gather(data_scaled, key = "Variable", value = "Value")

ggplot(df_crime_train_with_transformed, aes(x = Value)) +
  geom_histogram() +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histogram of Variables")
```




```{r}
# Create an empty list to store the transformed columns
transformed_columns_eval <- list()

# Define the names of columns to exclude from transformation because there variables response must be positive 
exclude_columns <- c("zn", "chas")  

# Iterate through the columns in df_crime_eval
for (col_name in names(df_crime_eval)) {
  # Convert the column to a list and check if it's numeric and not in the exclude list
  if (is.numeric(df_crime_eval[[col_name]]) && !(col_name %in% exclude_columns)) {
    col_list <- as.numeric(as.list(df_crime_eval[[col_name]]))
    
    # Find optimal lambda for Box-Cox transformation
    bc <- boxcox(col_list ~ 1, lambda = seq(-2, 2, 0.1))
    lambda_col <- bc$x[which.max(bc$y)]
    
    # Apply the Box-Cox transformation
    col_new <- ifelse(col_list==0, log(col_list), (col_list^lambda_col - 1) / lambda_col)
    
    # Store the transformed column in the list
    transformed_columns_eval[[col_name]] <- col_new
  }
}

# Convert the list of transformed columns into a DataFrame
df_transformed_eval <- as.data.frame(transformed_columns_eval)
```
```{r}
# Move 
df_crime_train_with_transformed_eval <- df_transformed_eval %>%
  dplyr::select(dis, lstat, medv, nox) %>%
  mutate(dis_t = dis, lstat_t = lstat, medv_t = medv, nox_t = nox)%>%
                dplyr::select(-c(dis, lstat, medv, nox))
```

```{r}
# Combine data frames by adding columns
result_eval <- cbind(df_crime_train_with_transformed_eval, df_crime_eval %>%
                dplyr::select(-c(dis, lstat, medv, nox)))
```


```{r}
# Apply min-max scaling to all three variables
data_scaled_eval <- result_eval
data_scaled_eval[] <- lapply(result_eval, rescale)
```
