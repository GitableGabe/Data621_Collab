View(features)
df_hate_training <- df_hate_training %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
df_hate_testing <- df_hate_testing %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
View(features)
df_hate_training <- df_hate_training %>% dplyr::select(-c('adult_victim_count',juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
test <- df_hate_training %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
View(test)
test <- df_hate_training %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)
library(scales)
library(MASS)
library(gridExtra)
library(psych)
library(skimr)
library(caret)
git_url<-
"https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"
df_hate_crime <-
read.csv(paste0(git_url,"hate_crime.csv"))
head(df_hate_crime,n=3)
summary(df_hate_crime)
print(skim(df_hate_crime))
ggcorr(df_hate_crime)
temp_data <- char2numeric(df_hate_crime)
(cor_matrix <- cor(temp_data, use='complete.obs'))
rm(git_url,temp_data)
# add binary column to each dataset
df_hate_crime <- df_hate_crime %>%
mutate(Anti_semitic_crimes = ifelse(grepl("Anti-Jewish",
bias_desc, ignore.case = TRUE), 1, 0))
# df_hate_crime <- df_hate_crime %>%
#   mutate(Violent = ifelse(grepl("*Assault*|*Abduction*|*Rape*|*Kidnapping*|*Murder*",
#                                      offense_name, ignore.case = TRUE), 1, 0))
# get counts
cnt_hate <- sum(df_hate_crime$Anti_semitic == 1)
total_hate<-nrow(df_hate_crime)
cat("Number of Anti_semitic column reports in hatecrime.csv is:",
cnt_hate," out of ",total_hate,"\n")
df_hate_corr <- char2numeric(df_hate_crime)
features <- df_hate_corr[, !(names(df_hate_corr) %in% c('Anti_semitic'))]
labels <- df_hate_corr$Anti_semitic_crimes
set.seed(123)
index <- createDataPartition(labels, p = 0.8, list = FALSE)
#training data
df_hate_training <- features[index, ]
labels_hate_training <- labels[index]
# Create testing dataset
df_hate_testing <- features[-index, ]
labels_hate_testing <- labels[-index]
test <- df_hate_training %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
# df_hate_testing <- df_hate_testing %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
df_hate_training <- df_hate_training %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
# df_hate_testing <- df_hate_testing %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)
library(scales)
library(MASS)
library(gridExtra)
library(psych)
library(skimr)
library(caret)
git_url<-
"https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"
df_hate_crime <-
read.csv(paste0(git_url,"hate_crime.csv"))
head(df_hate_crime,n=3)
summary(df_hate_crime)
print(skim(df_hate_crime))
ggcorr(df_hate_crime)
temp_data <- char2numeric(df_hate_crime)
(cor_matrix <- cor(temp_data, use='complete.obs'))
rm(git_url,temp_data)
# add binary column to each dataset
df_hate_crime <- df_hate_crime %>%
mutate(Anti_semitic_crimes = ifelse(grepl("Anti-Jewish",
bias_desc, ignore.case = TRUE), 1, 0))
# df_hate_crime <- df_hate_crime %>%
#   mutate(Violent = ifelse(grepl("*Assault*|*Abduction*|*Rape*|*Kidnapping*|*Murder*",
#                                      offense_name, ignore.case = TRUE), 1, 0))
# get counts
cnt_hate <- sum(df_hate_crime$Anti_semitic == 1)
total_hate<-nrow(df_hate_crime)
cat("Number of Anti_semitic column reports in hatecrime.csv is:",
cnt_hate," out of ",total_hate,"\n")
df_hate_corr <- char2numeric(df_hate_crime)
features <- df_hate_corr[, !(names(df_hate_corr) %in% c('Anti_semitic'))]
labels <- df_hate_corr$Anti_semitic_crimes
set.seed(123)
index <- createDataPartition(labels, p = 0.8, list = FALSE)
#training data
df_hate_training <- features[index, ]
labels_hate_training <- labels[index]
# Create testing dataset
df_hate_testing <- features[-index, ]
labels_hate_testing <- labels[-index]
df_hate_training <- df_hate_training %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
df_hate_testing <- df_hate_testing %>% dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count,juvenile_offender_count,total_individual_victims))
df_hate_training %>%
gather() %>%
ggplot(aes(x = value)) +
geom_histogram(fill = "cadetblue") +
facet_wrap(~key, scales = "free")
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)
library(scales)
library(MASS)
library(gridExtra)
library(psych)
library(skimr)
library(caret)
git_url<-
"https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"
df_hate_crime <-
read.csv(paste0(git_url,"hate_crime.csv"))
head(df_hate_crime,n=3)
summary(df_hate_crime)
print(skim(df_hate_crime))
df_hate_crime <- df_hate_crime%>%
dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count
,juvenile_offender_count,total_individual_victims,
incident_date))
# add binary column to each dataset
df_hate_crime <- df_hate_crime %>%
mutate(Anti_semitic_crimes = ifelse(grepl("Anti-Jewish",
bias_desc, ignore.case = TRUE), 1, 0))
# df_hate_crime <- df_hate_crime %>%
#   mutate(Violent = ifelse(grepl("*Assault*|*Abduction*|*Rape*|*Kidnapping*
#|*Murder*",
#                                      offense_name, ignore.case = TRUE), 1, 0))
# get counts
cnt_hate <- sum(df_hate_crime$Anti_semitic == 1)
total_hate<-nrow(df_hate_crime)
cat("Number of Anti_semitic column reports in hatecrime.csv is:",
cnt_hate," out of ",total_hate,"\n")
df_hate_corr <- df_hate_crime
# frequency_map <- table(df_hate_crime$incident_id)
# df_hate_crime$incident_id_freq <- frequency_map[df_hate_crime$incident_id]
add_freq <- function(data, column_name) {
# Compute frequencies, including NAs
frequency_map <- table(data[[column_name]], useNA = "always")
# Create a new column with frequency encoding (including NAs)
new_col_name <- paste0(column_name, "_freq")
data[[new_col_name]] <- frequency_map[match(data[[column_name]], names(frequency_map))]
return(data)
}
# Loop through all columns and add frequency encoding columns (including NAs)
for (col in names(df_hate_corr)) {
df_hate_corr <- add_freq(df_hate_corr, col)
}
# selecting only numeric columns
df_hate_corr<-df_hate_corr%>%
dplyr::select(matches("_freq"), matches("^Anti"))
View(df_hate_corr)
str(df_hate_crime)
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)
library(scales)
library(MASS)
library(gridExtra)
library(psych)
library(skimr)
library(caret)
git_url<-
"https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"
df_hate_crime <-
read.csv(paste0(git_url,"hate_crime.csv"))
head(df_hate_crime,n=3)
summary(df_hate_crime)
str(df_hate_crime)
print(skim(df_hate_crime))
df_hate_crime <- df_hate_crime%>%
dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count
,juvenile_offender_count,total_individual_victims,
incident_date))
# add binary column to each dataset
df_hate_crime <- df_hate_crime %>%
mutate(Antisemitic_crimes = ifelse(grepl("Anti-Jewish",
bias_desc, ignore.case = TRUE), 1, 0))
# df_hate_crime <- df_hate_crime %>%
#   mutate(Violent = ifelse(grepl("*Assault*|*Abduction*|*Rape*|*Kidnapping*
#|*Murder*",
#                                      offense_name, ignore.case = TRUE), 1, 0))
# get counts
cnt_hate <- sum(df_hate_crime$Antisemitic == 1)
total_hate<-nrow(df_hate_crime)
cat("Number of Antisemitic column reports in hatecrime.csv is:",
cnt_hate," out of ",total_hate,"\n")
df_hate_corr <- df_hate_crime
# frequency_map <- table(df_hate_crime$incident_id)
# df_hate_crime$incident_id_freq <- frequency_map[df_hate_crime$incident_id]
add_freq <- function(data, column_name) {
# Compute frequencies, including NAs
frequency_map <- table(data[[column_name]], useNA = "always")
# Create a new column with frequency encoding (including NAs)
new_col_name <- paste0(column_name, "_freq")
data[[new_col_name]] <- frequency_map[match(data[[column_name]], names(frequency_map))]
return(data)
}
# Loop through all columns and add frequency encoding columns (including NAs)
for (col in names(df_hate_corr)) {
df_hate_corr <- add_freq(df_hate_corr, col)
}
# selecting only numeric columns
df_hate_corr<-df_hate_corr%>%
dplyr::select(matches("_freq"), matches("^Anti"))
set.seed(123)
train_indices <- sample(seq_len(nrow(df_hate_corr)), 0.8 * nrow(df_hate_corr))
# Create training dataset
df_hate_train <- df_hate_corr[train_indices, ]
# Create test dataset
df_hate_test <- df_hate_corr[-train_indices, ]
rm(git_url,col,total_hate,train_indices,cnt_hate, add_freq)
df_hate_train %>%
dplyr::select( ends_with("_freq"))%>%
gather() %>%
ggplot(aes(x = value)) +
geom_histogram(fill = "cadetblue") +
facet_wrap(~key, scales = "free")
df_hate_test %>%
dplyr::select( ends_with("_freq"))%>%
gather() %>%
ggplot(aes(x = value)) +
geom_histogram(fill = "cadetblue") +
facet_wrap(~key, scales = "free")
ggcorr(df_hate_crime%>%
dplyr::select(-matches("_freq")))
(cor_matrix <- cor(df_hate_train))
df_hate_train<-as.data.frame.matrix(df_hate_train)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_train$data_year_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_data_year <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_data_year_freq <- (freq_list^lambda_data_year-1)/lambda_data_year
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_train$data_year_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_train$ori_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_ori <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_ori_freq <- (freq_list^lambda_ori-1)/lambda_ori
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_train$data_year_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_train$pug_agency_name_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_pug_agency_name <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_pug_agency_name_freq <- (freq_list^lambda_pug_agency_name-1)/lambda_pug_agency_name
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_train$pug_agency_name_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_train$state_abbr_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_state_abbr <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_state_abbr_freq <- (freq_list^lambda_state_abbr-1)/lambda_state_abbr
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_train$state_abbr_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_train$state_name_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_state_name <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_state_name_freq <- (freq_list^lambda_state_name-1)/lambda_state_name
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_train$state_name_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_train$bias_desc_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_bias_desc <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_bias_desc_freq <- (freq_list^lambda_bias_desc-1)/lambda_bias_desc
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_train$bias_desc_freq)
df_temp <- df_hate_train
df_train_model <- cbind(df_temp,
as.data.frame(norm_bias_desc_freq),
as.data.frame(norm_data_year_freq),
as.data.frame(norm_ori_freq),
as.data.frame(norm_pug_agency_name_freq),
as.data.frame(norm_state_abbr_freq),
as.data.frame(norm_state_name_freq))
rm(df_temp)
df_hate_train<-as.data.frame.matrix(df_hate_train)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_test$data_year_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_data_year <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_data_year_freq <- (freq_list^lambda_data_year-1)/lambda_data_year
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_test$data_year_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_test$ori_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_ori <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_ori_freq <- (freq_list^lambda_ori-1)/lambda_ori
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_test$data_year_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_test$pug_agency_name_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_pug_agency_name <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_pug_agency_name_freq <- (freq_list^lambda_pug_agency_name-1)/lambda_pug_agency_name
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_test$pug_agency_name_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_test$state_abbr_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_state_abbr <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_state_abbr_freq <- (freq_list^lambda_state_abbr-1)/lambda_state_abbr
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_test$state_abbr_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_test$state_name_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_state_name <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_state_name_freq <- (freq_list^lambda_state_name-1)/lambda_state_name
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_test$state_name_freq)
# Convert a DataFrame column to a list
freq_list <- as.numeric(as.list(df_hate_test$bias_desc_freq))
#find optimal lambda for Box-Cox transformation
bc <- boxcox(freq_list~ 1, lambda = seq(-2,2,0.1))
lambda_bias_desc <- bc$x[which.max(bc$y)]
# Apply the Box-Cox transformation
norm_bias_desc_freq <- (freq_list^lambda_bias_desc-1)/lambda_bias_desc
rm(bc,freq_list)
# hist(data_year_freq_norm )
# hist(df_hate_test$bias_desc_freq)
df_temp <- df_hate_test
df_test_model <- cbind(df_temp,
as.data.frame(norm_bias_desc_freq),
as.data.frame(norm_data_year_freq),
as.data.frame(norm_ori_freq),
as.data.frame(norm_pug_agency_name_freq),
as.data.frame(norm_state_abbr_freq),
as.data.frame(norm_state_name_freq))
rm(df_temp)
View(df_hate_corr)
df_hate_crime %>%
scale() %>%
as.data.frame() %>%
stack() %>%
ggplot(aes(x = ind, y = values)) +
geom_boxplot() +
labs(title = 'Boxplot Training (scaled)',
x = 'Variables',
y = 'Normalized_Values')+
theme(axis.text.x=element_text(size=10, angle=90))
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)
library(scales)
library(MASS)
library(gridExtra)
library(psych)
library(skimr)
library(caret)
git_url<-
"https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"
df_hate_crime <-
read.csv(paste0(git_url,"hate_crime.csv"))
head(df_hate_crime,n=3)
summary(df_hate_crime)
str(df_hate_crime)
print(skim(df_hate_crime))
df_hate_crime %>%
scale() %>%
as.data.frame() %>%
stack() %>%
ggplot(aes(x = ind, y = values)) +
geom_boxplot() +
labs(title = 'Boxplot Training (scaled)',
x = 'Variables',
y = 'Normalized_Values')+
theme(axis.text.x=element_text(size=10, angle=90))
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Hmisc)
library(corrplot)
library(PerformanceAnalytics)
library(scales)
library(MASS)
library(gridExtra)
library(psych)
library(skimr)
library(caret)
git_url<-
"https://raw.githubusercontent.com/GitableGabe/Data621_Data/main/"
df_hate_crime <-
read.csv(paste0(git_url,"hate_crime.csv"))
head(df_hate_crime,n=3)
summary(df_hate_crime)
str(df_hate_crime)
print(skim(df_hate_crime))
df_hate_crime <- df_hate_crime%>%
dplyr::select(-c(adult_victim_count,juvenile_victim_count,adult_offender_count
,juvenile_offender_count,total_individual_victims,
incident_date))
# add binary column to each dataset
df_hate_crime <- df_hate_crime %>%
mutate(Antisemitic_crimes = ifelse(grepl("Anti-Jewish",
bias_desc, ignore.case = TRUE), 1, 0))
# df_hate_crime <- df_hate_crime %>%
#   mutate(Violent = ifelse(grepl("*Assault*|*Abduction*|*Rape*|*Kidnapping*
#|*Murder*",
#                                      offense_name, ignore.case = TRUE), 1, 0))
# get counts
cnt_hate <- sum(df_hate_crime$Antisemitic == 1)
total_hate<-nrow(df_hate_crime)
cat("Number of Antisemitic column reports in hatecrime.csv is:",
cnt_hate," out of ",total_hate,"\n")
df_hate_corr <- df_hate_crime
# frequency_map <- table(df_hate_crime$incident_id)
# df_hate_crime$incident_id_freq <- frequency_map[df_hate_crime$incident_id]
add_freq <- function(data, column_name) {
# Compute frequencies, including NAs
frequency_map <- table(data[[column_name]], useNA = "always")
# Create a new column with frequency encoding (including NAs)
new_col_name <- paste0(column_name, "_freq")
data[[new_col_name]] <- frequency_map[match(data[[column_name]], names(frequency_map))]
return(data)
}
# Loop through all columns and add frequency encoding columns (including NAs)
for (col in names(df_hate_corr)) {
df_hate_corr <- add_freq(df_hate_corr, col)
}
# selecting only numeric columns
df_hate_corr<-df_hate_corr%>%
dplyr::select(matches("_freq"), matches("^Anti"))
df_hate_corr %>%
scale() %>%
as.data.frame() %>%
stack() %>%
ggplot(aes(x = ind, y = values)) +
geom_boxplot() +
labs(title = 'Boxplot Training (scaled)',
x = 'Variables',
y = 'Normalized_Values')+
theme(axis.text.x=element_text(size=10, angle=90))
df_hate_corr %>%
scale() %>%
as.data.frame() %>%
stack() %>%
ggplot(aes(x = ind, y = values)) +
geom_boxplot() +
labs(title = 'Boxplot Training (scaled)',
x = 'Variables',
y = 'Normalized_Values')+
theme(axis.text.x=element_text(size=10, angle=90))
